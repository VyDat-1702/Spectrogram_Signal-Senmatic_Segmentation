{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11488043,"sourceType":"datasetVersion","datasetId":7200796}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nguyenlamvydat/ai-senseg?scriptVersionId=237135063\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import random_split\nfrom torchvision import transforms\nfrom torch.optim import Adam\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nfrom torchmetrics.classification import MulticlassJaccardIndex, MulticlassAccuracy\nimport copy\nfrom torchsummary import summary","metadata":{"_uuid":"e87228af-b36c-4a7c-bd51-774167c2837e","_cell_guid":"53987e54-6707-4163-9919-fe4283aa802b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-01T02:39:50.881025Z","iopub.execute_input":"2025-05-01T02:39:50.881245Z","iopub.status.idle":"2025-05-01T02:39:50.88553Z","shell.execute_reply.started":"2025-05-01T02:39:50.881224Z","shell.execute_reply":"2025-05-01T02:39:50.884782Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class SemanticSegmentationDataset(Dataset):\n    def __init__(self, image_dir, label_dir, transform=None):\n        self.image_dir = image_dir\n        self.label_dir = label_dir\n        self.transform = transform\n        self.image_paths = sorted([os.path.join(image_dir, img) for img in os.listdir(image_dir)])\n        self.label_paths = sorted([os.path.join(label_dir, lbl) for lbl in os.listdir(label_dir)])\n        self.class_colors = {\n            (2, 0, 0): 0,       \n            (127, 0, 0): 1,     \n            (248, 163, 191): 2  \n        }\n    \n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image = cv2.imread(self.image_paths[idx])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        label = cv2.imread(self.label_paths[idx])\n        label = cv2.cvtColor(label, cv2.COLOR_BGR2RGB)\n\n        label_mask = np.zeros(label.shape[:2], dtype=np.uint8)\n        for rgb, idx in self.class_colors.items():\n            label_mask[np.all(label == rgb, axis=-1)] = idx\n\n        if self.transform:\n            image = self.transform(image)\n            label_mask = torch.from_numpy(label_mask).long()\n\n        return image, label_mask\n\ntrain_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor()\n])\n\ndataset = SemanticSegmentationDataset(\n    image_dir='/kaggle/input/spectro/input',\n    label_dir='/kaggle/input/spectro/label',\n    transform=train_transform)\n\ntotal_size = len(dataset)\ntrain_size = int(0.8 * total_size)  \nval_size = total_size - train_size  \ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\nprint(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}\")\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"_uuid":"a7ceb03d-ca41-412f-a103-a47c12ee3e6d","_cell_guid":"8d0f3667-5bb9-4e5c-a6b0-6401759eb7d6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-01T02:39:50.886429Z","iopub.execute_input":"2025-05-01T02:39:50.886673Z","iopub.status.idle":"2025-05-01T02:39:50.920458Z","shell.execute_reply.started":"2025-05-01T02:39:50.886652Z","shell.execute_reply":"2025-05-01T02:39:50.919844Z"}},"outputs":[{"name":"stdout","text":"Train size: 4800, Validation size: 1200\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n# Channel Attention\nclass ChannelAttention(nn.Module):\n    def __init__(self, in_channels, reduction=16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n        intermediate_channels = max(1, in_channels // reduction)\n        self.fc = nn.Sequential(\n            nn.Conv2d(in_channels, intermediate_channels, 1, bias=False),\n            nn.ReLU(),\n            nn.Conv2d(intermediate_channels, in_channels, 1, bias=False)\n        )\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.fc(self.avg_pool(x))\n        max_out = self.fc(self.max_pool(x))\n        out = avg_out + max_out\n        return self.sigmoid(out) * x\n\n# Spatial Attention\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        out = torch.cat([avg_out, max_out], dim=1)\n        out = self.conv(out)\n        return self.sigmoid(out) * x\n\n# CBAM Module\nclass CBAM(nn.Module):\n    def __init__(self, in_channels, reduction=16, kernel_size=7):\n        super(CBAM, self).__init__()\n        self.channel_attention = ChannelAttention(in_channels, reduction)\n        self.spatial_attention = SpatialAttention(kernel_size)\n\n    def forward(self, x):\n        x = self.channel_attention(x)\n        x = self.spatial_attention(x)\n        return x\n\n# Depthwise Separable Convolution\nclass DWConv(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(DWConv, self).__init__()\n        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride,\n                                   padding=1, groups=in_channels, bias=False)\n        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1,\n                                   padding=0, bias=False)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.depthwise(x)\n        x = self.pointwise(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\n# Multi-scale Feature Extraction\nclass MultiScaleBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(MultiScaleBlock, self).__init__()\n        branch_channels = out_channels // 3\n\n        self.branch1 = DWConv(in_channels, branch_channels)\n\n        self.branch2 = nn.Sequential(\n            nn.Conv2d(in_channels, branch_channels, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(branch_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(branch_channels, branch_channels, kernel_size=5, padding=2, bias=False),\n            nn.BatchNorm2d(branch_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        self.branch3 = nn.Sequential(\n            nn.Conv2d(in_channels, branch_channels, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(branch_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        concat_channels = branch_channels * 3\n        self.cbam = CBAM(concat_channels, reduction=16)\n        self.adjust_channels = nn.Conv2d(concat_channels, out_channels, kernel_size=1, bias=False)\n\n    def forward(self, x):\n        b1 = self.branch1(x)\n        b2 = self.branch2(x)\n        b3 = self.branch3(x)\n        out = torch.cat([b1, b2, b3], dim=1)\n        out = self.cbam(out)\n        out = self.adjust_channels(out)\n        return out\n\n# SSNet\nclass SSNet(nn.Module):\n    def __init__(self, num_classes=3):\n        super(SSNet, self).__init__()\n\n        # Encoder\n        self.enc1 = MultiScaleBlock(3, 16)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.enc2 = MultiScaleBlock(16, 32)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.enc3 = MultiScaleBlock(32, 64)\n        self.pool3 = nn.MaxPool2d(2, 2)\n        self.enc4 = DWConv(64, 128)\n\n        # Decoder\n        self.up1 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n            nn.Conv2d(128, 64, kernel_size=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True)\n        )\n        self.dec1 = MultiScaleBlock(128, 64)\n\n        self.up2 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n            nn.Conv2d(64, 32, kernel_size=1, bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True)\n        )\n        self.dec2 = MultiScaleBlock(64, 32)\n\n        self.up3 = nn.Sequential(\n            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n            nn.Conv2d(32, 16, kernel_size=1, bias=False),\n            nn.BatchNorm2d(16),\n            nn.ReLU(inplace=True)\n        )\n        self.dec3 = MultiScaleBlock(32, 16)\n\n        self.final = nn.Conv2d(16, num_classes, kernel_size=1)\n\n    def forward(self, x):\n        e1 = self.enc1(x)\n        p1 = self.pool1(e1)\n        e2 = self.enc2(p1)\n        p2 = self.pool2(e2)\n        e3 = self.enc3(p2)\n        p3 = self.pool3(e3)\n        e4 = self.enc4(p3)\n\n        d1 = self.up1(e4)\n        d1 = torch.cat([d1, e3], dim=1)\n        d1 = self.dec1(d1)\n\n        d2 = self.up2(d1)\n        d2 = torch.cat([d2, e2], dim=1)\n        d2 = self.dec2(d2)\n\n        d3 = self.up3(d2)\n        d3 = torch.cat([d3, e1], dim=1)\n        d3 = self.dec3(d3)\n\n        out = self.final(d3)\n        return out\n","metadata":{"_uuid":"5905f74f-bf83-4bac-a6f4-ba0110e35704","_cell_guid":"c9a74cbf-a852-46d7-9235-9c224b605482","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-01T02:39:50.921156Z","iopub.execute_input":"2025-05-01T02:39:50.92137Z","iopub.status.idle":"2025-05-01T02:39:50.939872Z","shell.execute_reply.started":"2025-05-01T02:39:50.92134Z","shell.execute_reply":"2025-05-01T02:39:50.938963Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def train_epoch(model, dataloader, criterion, optimizer, device, num_classes):\n    model.train()\n    running_loss = 0.0  \n    accuracy_metric = MulticlassAccuracy(num_classes=num_classes).to(device)\n    iou_metric = MulticlassJaccardIndex(num_classes=num_classes).to(device)\n    pbar = tqdm(dataloader, desc='Training', unit='batch')\n    for images, labels in pbar:\n        images = images.to(device)\n        labels = labels.to(device)       \n        optimizer.zero_grad()\n        outputs = model(images)    \n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()   \n        running_loss += loss.item() * images.size(0)      \n        preds = torch.argmax(outputs, dim=1)     \n        accuracy_metric(preds, labels)\n        iou_metric(preds, labels)\n        pbar.set_postfix({\n            'Batch Loss': f'{loss.item():.4f}',\n            'Mean Accuracy': f'{accuracy_metric.compute():.4f}',\n            'Mean IoU': f'{iou_metric.compute():.4f}',\n        }) \n    epoch_loss = running_loss / len(dataloader.dataset)  \n    mean_accuracy = accuracy_metric.compute().cpu().numpy()\n    mean_iou = iou_metric.compute().cpu().numpy()\n   \n    return epoch_loss, mean_accuracy, mean_iou","metadata":{"_uuid":"5b8e1b65-0673-4614-b3b9-ce50e643f3cb","_cell_guid":"d206c6ca-dbcb-43d2-89ef-c602ab189ec2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-01T02:39:50.940771Z","iopub.execute_input":"2025-05-01T02:39:50.94101Z","iopub.status.idle":"2025-05-01T02:39:50.959669Z","shell.execute_reply.started":"2025-05-01T02:39:50.940979Z","shell.execute_reply":"2025-05-01T02:39:50.958855Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def evaluate(model, dataloader, criterion, device, num_classes):\n    model.eval()\n    running_loss = 0.0    \n    accuracy_metric = MulticlassAccuracy(num_classes=num_classes).to(device)\n    iou_metric = MulticlassJaccardIndex(num_classes=num_classes).to(device)\n    pbar = tqdm(dataloader, desc='Evaluating', unit='batch')\n    with torch.no_grad():\n        for images, labels in pbar:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item() * images.size(0)\n            preds = torch.argmax(outputs, dim=1)\n            # Update metrics\n            accuracy_metric(preds, labels)\n            iou_metric(preds, labels)\n            # Update tqdm description with metrics\n            pbar.set_postfix({\n                'Batch Loss': f'{loss.item():.4f}',\n                'Mean Accuracy': f'{accuracy_metric.compute():.4f}',\n                'Mean IoU': f'{iou_metric.compute():.4f}',\n            })\n    \n    epoch_loss = running_loss / len(dataloader.dataset)\n    mean_accuracy = accuracy_metric.compute().cpu().numpy()\n    mean_iou = iou_metric.compute().cpu().numpy()\n    \n    return epoch_loss, mean_accuracy, mean_iou","metadata":{"_uuid":"ae689ece-c9a1-4c8d-b38a-06853eb0e003","_cell_guid":"98cd7830-a827-465c-a9b1-e4b6fa02f12a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-01T02:39:50.960454Z","iopub.execute_input":"2025-05-01T02:39:50.960768Z","iopub.status.idle":"2025-05-01T02:39:50.97675Z","shell.execute_reply.started":"2025-05-01T02:39:50.960737Z","shell.execute_reply":"2025-05-01T02:39:50.975953Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Đảm bảo bạn có ít nhất 2 GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nif torch.cuda.device_count() < 2:\n    print(\"1 GPU\")\nelse:\n    print(f\"{torch.cuda.device_count()} GPUs.\")\n\nclasses = 3  \nmodel = SSNet(classes).to(device)\n\ndef count_parameters(model):  \n    return sum(p.numel() for p in model.parameters())\n\ntotal_params = count_parameters(model)\nprint(f\"Total parameters: {total_params}\")\n\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(model) \n\n# Kiểm tra mô hình\nsummary(model, (3, 256, 256))\n\ncriterion = nn.CrossEntropyLoss()  \noptimizer = Adam(model.parameters(), lr=0.001)\nnum_epochs = 10\n\nepoch_saved = 0\nbest_val_mAcc = 0.0  \nbest_model_state = None\n\nfor epoch in range(num_epochs):\n    epoch_loss_train, mAcc_train, mIoU_train = train_epoch(model, train_dataloader, criterion, optimizer, device, classes)\n    epoch_loss_val, mAcc_val, mIoU_val = evaluate(model, val_dataloader, criterion, device, classes)\n    \n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n    print(f\"Train Loss: {epoch_loss_train:.4f}, Mean Accuracy: {mAcc_train:.4f}, Mean IoU: {mIoU_train:.4f}\")\n    print(f\"Validation Loss: {epoch_loss_val:.4f}, Mean Accuracy: {mAcc_val:.4f}, Mean IoU: {mIoU_val:.4f}\")\n\n    if mAcc_val >= best_val_mAcc:\n        epoch_saved = epoch + 1 \n        best_val_mAcc = mAcc_val\n        best_model_state = copy.deepcopy(model.state_dict())\n    \nprint(\"===================\")\nprint(f\"Best Model at epoch : {epoch_saved}\")\nmodel.load_state_dict(best_model_state)\nif isinstance(model, torch.nn.DataParallel):\n    model = model.module\nmodel_save = torch.jit.script(model)\nmodel_save.save(\"Nhom7.pt\")\n# Check again\nmodel = torch.jit.load(\"Nhom7.pt\")\nepoch_loss_val, mAcc_val, mIoU_val = evaluate(model, val_dataloader, criterion, device, classes)\nprint(f\"Validation Loss: {epoch_loss_val:.4f}, Mean Accuracy: {mAcc_val:.4f}, Mean IoU: {mIoU_val:.4f}\")","metadata":{"_uuid":"b224d155-f1dd-4929-88f9-149e10161523","_cell_guid":"3b1caf4d-ad2b-4f3a-897a-afd249c260e1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-01T02:39:50.97743Z","iopub.execute_input":"2025-05-01T02:39:50.977706Z","iopub.status.idle":"2025-05-01T03:02:31.199236Z","shell.execute_reply.started":"2025-05-01T02:39:50.977678Z","shell.execute_reply":"2025-05-01T03:02:31.198285Z"}},"outputs":[{"name":"stdout","text":"1 GPU\nTotal parameters: 145755\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1          [-1, 3, 256, 256]              27\n            Conv2d-2          [-1, 5, 256, 256]              15\n       BatchNorm2d-3          [-1, 5, 256, 256]              10\n              ReLU-4          [-1, 5, 256, 256]               0\n            DWConv-5          [-1, 5, 256, 256]               0\n            Conv2d-6          [-1, 5, 256, 256]             135\n       BatchNorm2d-7          [-1, 5, 256, 256]              10\n              ReLU-8          [-1, 5, 256, 256]               0\n            Conv2d-9          [-1, 5, 256, 256]             625\n      BatchNorm2d-10          [-1, 5, 256, 256]              10\n             ReLU-11          [-1, 5, 256, 256]               0\n           Conv2d-12          [-1, 5, 256, 256]             135\n      BatchNorm2d-13          [-1, 5, 256, 256]              10\n             ReLU-14          [-1, 5, 256, 256]               0\nAdaptiveAvgPool2d-15             [-1, 15, 1, 1]               0\n           Conv2d-16              [-1, 1, 1, 1]              15\n             ReLU-17              [-1, 1, 1, 1]               0\n           Conv2d-18             [-1, 15, 1, 1]              15\nAdaptiveMaxPool2d-19             [-1, 15, 1, 1]               0\n           Conv2d-20              [-1, 1, 1, 1]              15\n             ReLU-21              [-1, 1, 1, 1]               0\n           Conv2d-22             [-1, 15, 1, 1]              15\n          Sigmoid-23             [-1, 15, 1, 1]               0\n ChannelAttention-24         [-1, 15, 256, 256]               0\n           Conv2d-25          [-1, 1, 256, 256]              98\n          Sigmoid-26          [-1, 1, 256, 256]               0\n SpatialAttention-27         [-1, 15, 256, 256]               0\n             CBAM-28         [-1, 15, 256, 256]               0\n           Conv2d-29         [-1, 16, 256, 256]             240\n  MultiScaleBlock-30         [-1, 16, 256, 256]               0\n        MaxPool2d-31         [-1, 16, 128, 128]               0\n           Conv2d-32         [-1, 16, 128, 128]             144\n           Conv2d-33         [-1, 10, 128, 128]             160\n      BatchNorm2d-34         [-1, 10, 128, 128]              20\n             ReLU-35         [-1, 10, 128, 128]               0\n           DWConv-36         [-1, 10, 128, 128]               0\n           Conv2d-37         [-1, 10, 128, 128]           1,440\n      BatchNorm2d-38         [-1, 10, 128, 128]              20\n             ReLU-39         [-1, 10, 128, 128]               0\n           Conv2d-40         [-1, 10, 128, 128]           2,500\n      BatchNorm2d-41         [-1, 10, 128, 128]              20\n             ReLU-42         [-1, 10, 128, 128]               0\n           Conv2d-43         [-1, 10, 128, 128]           1,440\n      BatchNorm2d-44         [-1, 10, 128, 128]              20\n             ReLU-45         [-1, 10, 128, 128]               0\nAdaptiveAvgPool2d-46             [-1, 30, 1, 1]               0\n           Conv2d-47              [-1, 1, 1, 1]              30\n             ReLU-48              [-1, 1, 1, 1]               0\n           Conv2d-49             [-1, 30, 1, 1]              30\nAdaptiveMaxPool2d-50             [-1, 30, 1, 1]               0\n           Conv2d-51              [-1, 1, 1, 1]              30\n             ReLU-52              [-1, 1, 1, 1]               0\n           Conv2d-53             [-1, 30, 1, 1]              30\n          Sigmoid-54             [-1, 30, 1, 1]               0\n ChannelAttention-55         [-1, 30, 128, 128]               0\n           Conv2d-56          [-1, 1, 128, 128]              98\n          Sigmoid-57          [-1, 1, 128, 128]               0\n SpatialAttention-58         [-1, 30, 128, 128]               0\n             CBAM-59         [-1, 30, 128, 128]               0\n           Conv2d-60         [-1, 32, 128, 128]             960\n  MultiScaleBlock-61         [-1, 32, 128, 128]               0\n        MaxPool2d-62           [-1, 32, 64, 64]               0\n           Conv2d-63           [-1, 32, 64, 64]             288\n           Conv2d-64           [-1, 21, 64, 64]             672\n      BatchNorm2d-65           [-1, 21, 64, 64]              42\n             ReLU-66           [-1, 21, 64, 64]               0\n           DWConv-67           [-1, 21, 64, 64]               0\n           Conv2d-68           [-1, 21, 64, 64]           6,048\n      BatchNorm2d-69           [-1, 21, 64, 64]              42\n             ReLU-70           [-1, 21, 64, 64]               0\n           Conv2d-71           [-1, 21, 64, 64]          11,025\n      BatchNorm2d-72           [-1, 21, 64, 64]              42\n             ReLU-73           [-1, 21, 64, 64]               0\n           Conv2d-74           [-1, 21, 64, 64]           6,048\n      BatchNorm2d-75           [-1, 21, 64, 64]              42\n             ReLU-76           [-1, 21, 64, 64]               0\nAdaptiveAvgPool2d-77             [-1, 63, 1, 1]               0\n           Conv2d-78              [-1, 3, 1, 1]             189\n             ReLU-79              [-1, 3, 1, 1]               0\n           Conv2d-80             [-1, 63, 1, 1]             189\nAdaptiveMaxPool2d-81             [-1, 63, 1, 1]               0\n           Conv2d-82              [-1, 3, 1, 1]             189\n             ReLU-83              [-1, 3, 1, 1]               0\n           Conv2d-84             [-1, 63, 1, 1]             189\n          Sigmoid-85             [-1, 63, 1, 1]               0\n ChannelAttention-86           [-1, 63, 64, 64]               0\n           Conv2d-87            [-1, 1, 64, 64]              98\n          Sigmoid-88            [-1, 1, 64, 64]               0\n SpatialAttention-89           [-1, 63, 64, 64]               0\n             CBAM-90           [-1, 63, 64, 64]               0\n           Conv2d-91           [-1, 64, 64, 64]           4,032\n  MultiScaleBlock-92           [-1, 64, 64, 64]               0\n        MaxPool2d-93           [-1, 64, 32, 32]               0\n           Conv2d-94           [-1, 64, 32, 32]             576\n           Conv2d-95          [-1, 128, 32, 32]           8,192\n      BatchNorm2d-96          [-1, 128, 32, 32]             256\n             ReLU-97          [-1, 128, 32, 32]               0\n           DWConv-98          [-1, 128, 32, 32]               0\n         Upsample-99          [-1, 128, 64, 64]               0\n          Conv2d-100           [-1, 64, 64, 64]           8,192\n     BatchNorm2d-101           [-1, 64, 64, 64]             128\n            ReLU-102           [-1, 64, 64, 64]               0\n          Conv2d-103          [-1, 128, 64, 64]           1,152\n          Conv2d-104           [-1, 21, 64, 64]           2,688\n     BatchNorm2d-105           [-1, 21, 64, 64]              42\n            ReLU-106           [-1, 21, 64, 64]               0\n          DWConv-107           [-1, 21, 64, 64]               0\n          Conv2d-108           [-1, 21, 64, 64]          24,192\n     BatchNorm2d-109           [-1, 21, 64, 64]              42\n            ReLU-110           [-1, 21, 64, 64]               0\n          Conv2d-111           [-1, 21, 64, 64]          11,025\n     BatchNorm2d-112           [-1, 21, 64, 64]              42\n            ReLU-113           [-1, 21, 64, 64]               0\n          Conv2d-114           [-1, 21, 64, 64]          24,192\n     BatchNorm2d-115           [-1, 21, 64, 64]              42\n            ReLU-116           [-1, 21, 64, 64]               0\nAdaptiveAvgPool2d-117             [-1, 63, 1, 1]               0\n          Conv2d-118              [-1, 3, 1, 1]             189\n            ReLU-119              [-1, 3, 1, 1]               0\n          Conv2d-120             [-1, 63, 1, 1]             189\nAdaptiveMaxPool2d-121             [-1, 63, 1, 1]               0\n          Conv2d-122              [-1, 3, 1, 1]             189\n            ReLU-123              [-1, 3, 1, 1]               0\n          Conv2d-124             [-1, 63, 1, 1]             189\n         Sigmoid-125             [-1, 63, 1, 1]               0\nChannelAttention-126           [-1, 63, 64, 64]               0\n          Conv2d-127            [-1, 1, 64, 64]              98\n         Sigmoid-128            [-1, 1, 64, 64]               0\nSpatialAttention-129           [-1, 63, 64, 64]               0\n            CBAM-130           [-1, 63, 64, 64]               0\n          Conv2d-131           [-1, 64, 64, 64]           4,032\n MultiScaleBlock-132           [-1, 64, 64, 64]               0\n        Upsample-133         [-1, 64, 128, 128]               0\n          Conv2d-134         [-1, 32, 128, 128]           2,048\n     BatchNorm2d-135         [-1, 32, 128, 128]              64\n            ReLU-136         [-1, 32, 128, 128]               0\n          Conv2d-137         [-1, 64, 128, 128]             576\n          Conv2d-138         [-1, 10, 128, 128]             640\n     BatchNorm2d-139         [-1, 10, 128, 128]              20\n            ReLU-140         [-1, 10, 128, 128]               0\n          DWConv-141         [-1, 10, 128, 128]               0\n          Conv2d-142         [-1, 10, 128, 128]           5,760\n     BatchNorm2d-143         [-1, 10, 128, 128]              20\n            ReLU-144         [-1, 10, 128, 128]               0\n          Conv2d-145         [-1, 10, 128, 128]           2,500\n     BatchNorm2d-146         [-1, 10, 128, 128]              20\n            ReLU-147         [-1, 10, 128, 128]               0\n          Conv2d-148         [-1, 10, 128, 128]           5,760\n     BatchNorm2d-149         [-1, 10, 128, 128]              20\n            ReLU-150         [-1, 10, 128, 128]               0\nAdaptiveAvgPool2d-151             [-1, 30, 1, 1]               0\n          Conv2d-152              [-1, 1, 1, 1]              30\n            ReLU-153              [-1, 1, 1, 1]               0\n          Conv2d-154             [-1, 30, 1, 1]              30\nAdaptiveMaxPool2d-155             [-1, 30, 1, 1]               0\n          Conv2d-156              [-1, 1, 1, 1]              30\n            ReLU-157              [-1, 1, 1, 1]               0\n          Conv2d-158             [-1, 30, 1, 1]              30\n         Sigmoid-159             [-1, 30, 1, 1]               0\nChannelAttention-160         [-1, 30, 128, 128]               0\n          Conv2d-161          [-1, 1, 128, 128]              98\n         Sigmoid-162          [-1, 1, 128, 128]               0\nSpatialAttention-163         [-1, 30, 128, 128]               0\n            CBAM-164         [-1, 30, 128, 128]               0\n          Conv2d-165         [-1, 32, 128, 128]             960\n MultiScaleBlock-166         [-1, 32, 128, 128]               0\n        Upsample-167         [-1, 32, 256, 256]               0\n          Conv2d-168         [-1, 16, 256, 256]             512\n     BatchNorm2d-169         [-1, 16, 256, 256]              32\n            ReLU-170         [-1, 16, 256, 256]               0\n          Conv2d-171         [-1, 32, 256, 256]             288\n          Conv2d-172          [-1, 5, 256, 256]             160\n     BatchNorm2d-173          [-1, 5, 256, 256]              10\n            ReLU-174          [-1, 5, 256, 256]               0\n          DWConv-175          [-1, 5, 256, 256]               0\n          Conv2d-176          [-1, 5, 256, 256]           1,440\n     BatchNorm2d-177          [-1, 5, 256, 256]              10\n            ReLU-178          [-1, 5, 256, 256]               0\n          Conv2d-179          [-1, 5, 256, 256]             625\n     BatchNorm2d-180          [-1, 5, 256, 256]              10\n            ReLU-181          [-1, 5, 256, 256]               0\n          Conv2d-182          [-1, 5, 256, 256]           1,440\n     BatchNorm2d-183          [-1, 5, 256, 256]              10\n            ReLU-184          [-1, 5, 256, 256]               0\nAdaptiveAvgPool2d-185             [-1, 15, 1, 1]               0\n          Conv2d-186              [-1, 1, 1, 1]              15\n            ReLU-187              [-1, 1, 1, 1]               0\n          Conv2d-188             [-1, 15, 1, 1]              15\nAdaptiveMaxPool2d-189             [-1, 15, 1, 1]               0\n          Conv2d-190              [-1, 1, 1, 1]              15\n            ReLU-191              [-1, 1, 1, 1]               0\n          Conv2d-192             [-1, 15, 1, 1]              15\n         Sigmoid-193             [-1, 15, 1, 1]               0\nChannelAttention-194         [-1, 15, 256, 256]               0\n          Conv2d-195          [-1, 1, 256, 256]              98\n         Sigmoid-196          [-1, 1, 256, 256]               0\nSpatialAttention-197         [-1, 15, 256, 256]               0\n            CBAM-198         [-1, 15, 256, 256]               0\n          Conv2d-199         [-1, 16, 256, 256]             240\n MultiScaleBlock-200         [-1, 16, 256, 256]               0\n          Conv2d-201          [-1, 3, 256, 256]              51\n================================================================\nTotal params: 146,691\nTrainable params: 146,691\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.75\nForward/backward pass size (MB): 364.51\nParams size (MB): 0.56\nEstimated Total Size (MB): 365.82\n----------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [01:53<00:00,  1.32batch/s, Batch Loss=0.1473, Mean Accuracy=0.8908, Mean IoU=0.7184]\nEvaluating: 100%|██████████| 38/38 [00:18<00:00,  2.06batch/s, Batch Loss=0.2728, Mean Accuracy=0.8955, Mean IoU=0.7829]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 0.5088, Mean Accuracy: 0.8908, Mean IoU: 0.7184\nValidation Loss: 0.2344, Mean Accuracy: 0.8955, Mean IoU: 0.7829\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [01:54<00:00,  1.31batch/s, Batch Loss=0.0564, Mean Accuracy=0.9658, Mean IoU=0.9383]\nEvaluating: 100%|██████████| 38/38 [00:18<00:00,  2.03batch/s, Batch Loss=0.0455, Mean Accuracy=0.9771, Mean IoU=0.9569]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10\nTrain Loss: 0.0975, Mean Accuracy: 0.9658, Mean IoU: 0.9383\nValidation Loss: 0.0562, Mean Accuracy: 0.9771, Mean IoU: 0.9569\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [01:54<00:00,  1.31batch/s, Batch Loss=0.0508, Mean Accuracy=0.9748, Mean IoU=0.9547]\nEvaluating: 100%|██████████| 38/38 [00:19<00:00,  1.97batch/s, Batch Loss=0.0355, Mean Accuracy=0.9862, Mean IoU=0.9645]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10\nTrain Loss: 0.0579, Mean Accuracy: 0.9748, Mean IoU: 0.9547\nValidation Loss: 0.0426, Mean Accuracy: 0.9862, Mean IoU: 0.9645\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [01:55<00:00,  1.30batch/s, Batch Loss=0.0503, Mean Accuracy=0.9813, Mean IoU=0.9664]\nEvaluating: 100%|██████████| 38/38 [00:19<00:00,  1.99batch/s, Batch Loss=0.0260, Mean Accuracy=0.9869, Mean IoU=0.9728]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10\nTrain Loss: 0.0405, Mean Accuracy: 0.9813, Mean IoU: 0.9664\nValidation Loss: 0.0304, Mean Accuracy: 0.9869, Mean IoU: 0.9728\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [01:55<00:00,  1.30batch/s, Batch Loss=0.0409, Mean Accuracy=0.9762, Mean IoU=0.9568]\nEvaluating: 100%|██████████| 38/38 [00:19<00:00,  1.99batch/s, Batch Loss=0.0344, Mean Accuracy=0.9818, Mean IoU=0.9632]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10\nTrain Loss: 0.0484, Mean Accuracy: 0.9762, Mean IoU: 0.9568\nValidation Loss: 0.0421, Mean Accuracy: 0.9818, Mean IoU: 0.9632\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [01:55<00:00,  1.30batch/s, Batch Loss=0.0262, Mean Accuracy=0.9818, Mean IoU=0.9670]\nEvaluating: 100%|██████████| 38/38 [00:18<00:00,  2.00batch/s, Batch Loss=0.0216, Mean Accuracy=0.9844, Mean IoU=0.9729]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10\nTrain Loss: 0.0377, Mean Accuracy: 0.9818, Mean IoU: 0.9670\nValidation Loss: 0.0290, Mean Accuracy: 0.9844, Mean IoU: 0.9729\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [01:54<00:00,  1.30batch/s, Batch Loss=0.0279, Mean Accuracy=0.9842, Mean IoU=0.9717]\nEvaluating: 100%|██████████| 38/38 [00:19<00:00,  1.99batch/s, Batch Loss=0.0214, Mean Accuracy=0.9851, Mean IoU=0.9741]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/10\nTrain Loss: 0.0320, Mean Accuracy: 0.9842, Mean IoU: 0.9717\nValidation Loss: 0.0278, Mean Accuracy: 0.9851, Mean IoU: 0.9741\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [01:55<00:00,  1.30batch/s, Batch Loss=0.0226, Mean Accuracy=0.9855, Mean IoU=0.9740]\nEvaluating: 100%|██████████| 38/38 [00:19<00:00,  1.99batch/s, Batch Loss=0.0168, Mean Accuracy=0.9854, Mean IoU=0.9775]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/10\nTrain Loss: 0.0297, Mean Accuracy: 0.9855, Mean IoU: 0.9740\nValidation Loss: 0.0245, Mean Accuracy: 0.9854, Mean IoU: 0.9775\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [01:55<00:00,  1.30batch/s, Batch Loss=0.0214, Mean Accuracy=0.9868, Mean IoU=0.9762]\nEvaluating: 100%|██████████| 38/38 [00:18<00:00,  2.02batch/s, Batch Loss=0.0221, Mean Accuracy=0.9898, Mean IoU=0.9774]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/10\nTrain Loss: 0.0269, Mean Accuracy: 0.9868, Mean IoU: 0.9762\nValidation Loss: 0.0244, Mean Accuracy: 0.9898, Mean IoU: 0.9774\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 150/150 [01:55<00:00,  1.30batch/s, Batch Loss=0.0282, Mean Accuracy=0.9874, Mean IoU=0.9775]\nEvaluating: 100%|██████████| 38/38 [00:18<00:00,  2.03batch/s, Batch Loss=0.0230, Mean Accuracy=0.9910, Mean IoU=0.9789]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/10\nTrain Loss: 0.0256, Mean Accuracy: 0.9874, Mean IoU: 0.9775\nValidation Loss: 0.0231, Mean Accuracy: 0.9910, Mean IoU: 0.9789\n===================\nBest Model at epoch : 10\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 38/38 [00:19<00:00,  1.90batch/s, Batch Loss=0.0230, Mean Accuracy=0.9910, Mean IoU=0.9789]","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.0231, Mean Accuracy: 0.9910, Mean IoU: 0.9789\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"_uuid":"dfb781e7-b988-4b8f-befe-964df4a0f049","_cell_guid":"5a0a1818-a99b-4525-832c-9a59a45121c8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}